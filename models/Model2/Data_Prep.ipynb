{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download the Zip File from the link Given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://unearthed-exploresa.s3-ap-southeast-2.amazonaws.com/Unearthed_5_SARIG_Data_Package.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Extract the files in a desired folder\n",
    "Open this jupyter-notebook from that folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the `sarig_rs_chem_exp.csv` file for preparing our dataset. Since the size of file is around ~11 GB, we'll specify the columns that we need for analysis. We'll also be specifying the low_memory parameter.\n",
    "The columns we need are ->\n",
    "- 'LONGITUDE_GDA94'\n",
    "- 'LATITUDE_GDA94'\n",
    "- 'CHEM_CODE'\n",
    "- 'VALUE'\n",
    "- 'UNIT'\n",
    "\n",
    "If you wish to have a full look at the dataset, you can always remove the `usecols` parameter. Though, its highly likely that the kernel will crash. _Hack - You can specify nrows = 10 or 100 to preview the first few rows._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention either the complete or relative path of the sarig_rs_chem_exp.csv file\n",
    "path = '/home/xavian/Downloads/The_Gawler_Challenge/GeoChem_Data/Unearthed_5_SARIG_Data_Package/SARIG_Data_Package2_Exported20052020/sarig_rs_chem_exp.csv'\n",
    "data = pd.read_csv(path, low_memory=False, encoding = \"cp1252\", usecols = ['LONGITUDE_GDA94','LATITUDE_GDA94','CHEM_CODE', 'VALUE', 'UNIT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's view all the unique UNITS\n",
    "data.UNIT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be removing all the non-numeric characters -> '<>-'\n",
    "data['VALUE'] = data.VALUE.str.lstrip('<->')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be dropping all the values with AMOUNT less than 10\n",
    "data=data.drop(data[data['VALUE']=='0-10'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the datatype to numeric\n",
    "data[['VALUE']] = data[['VALUE']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's preview\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column - UNIT_PPM by converting all the other units to PPM\n",
    "data['UNIT_PPM'] = np.where(data.UNIT == 'ppb', data.VALUE/1000, (np.where(data.UNIT == '%', data.VALUE*10000, data.VALUE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the UNIT & VALUE Column\n",
    "data = data.drop(['UNIT', 'VALUE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the Chem codes we'll be dropping \n",
    "drop_min=[ 'LOI', 'H2O_plus', 'H2O_minus', 'Insol', 'Total',\n",
    "       'GoI', 'TOT/C', 'pH', 'EC', 'RADBK',\n",
    "       'RADTC', 'HMIN', 'H2O','CPS_gamma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop them!\n",
    "for i in drop_min:\n",
    "    print(i)\n",
    "    df=df.drop(df[ df['CHEM_CODE'] == i].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.CHEM_CODE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have `lxml` installed for the next step. It's not installed if you are in a conda environment. Install it using `pip install lxml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select unique chem codes at every individual location, we'll be calculating VALUE = UNIT_PPM * PRICE per KG\n",
    "link = \"https://en.wikipedia.org/wiki/Prices_of_chemical_elements\"\n",
    "tables = pd.read_html(link,header=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new column names\n",
    "table = tables[['Symbol', 'Name', 'Price[5]']]\n",
    "table=table.drop(index=0)\n",
    "table=table.rename(columns={\"Price[5]\": \"Price in USD/Kg\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the table\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make a dictionary with symbols as keys and price as Value\n",
    "s=table['Symbol'].to_list()\n",
    "p=table['Price in USD/Kg'].to_list()\n",
    "price_dict = {s[i]: p[i] for i in range(len(s))}\n",
    "\n",
    "# Now lets replace the price with a range, with a fixed value. For Ex\n",
    "price = {'Ti': '11.7','K': '13.6','Na': '3.43', 'Ca': '2.35', 'Ru': '10600',  'Zr': '37.1', 'Ge': '1010', 'Ir': '56200', 'Sr': '6.68', 'Ta': '312', 'Re': '4150','Nb': '85.6','La': '4.92', 'Li': '85.6','Ce': '4.71','As': '1.31', 'Ba': '0.275','Ti': '11.7', 'V': '385','F': '2.16'}\n",
    "price.update(price)\n",
    "\n",
    "# Lets check the Dictionary\n",
    "print(price_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemcode_list=df.CHEM_CODE.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets find the CHEM_CODE whose value we don't know[which are not in the 'price' dict]\n",
    "def uncommon(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value not in lst2] \n",
    "    return lst3 \n",
    "lst1 = s\n",
    "lst2 = a\n",
    "other=uncommon(lst1, lst2)\n",
    "print(other) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make a dict which will replace the 'other' CHEM_CODE with a specific element\n",
    "element=['U', 'Si', 'Al', 'Ti', 'Fe', 'Mn', 'Mg', 'Ca', 'Na', 'K', 'P', 'Fe', ' ', 'Fe', 'Cr', 'V', 'Th', 'W', 'Ta', 'Nb', ' ', 'Na', 'Ba', 'Ca', ' ', 'Ca', 'Mg', 'Ca', ' ', '-', ' ', ' ', 'Fe', 'Fe', 'Ni', 'V', 'Zn', 'Sr', 'Cu', 'Zr', 'Hf', 'Sr', '-', 'K', 'Fe', 'Co', '-', 'Cl']\n",
    "element_dict = {other[i]: element[i] for i in range(len(other))} \n",
    "print(element_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets make a new column so that we can make change without disturbing the original data\n",
    "df[['CHEM_CODE_N']]=df[['CHEM_CODE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Lets replace the 'other' CHEM_CODE using the 'element_dict'\n",
    "df=df.replace({\"CHEM_CODE_N\": element_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets drop some more dummy CHEM_CODE\n",
    "# Doing it seperately reduces its asymptotic complexity\n",
    "indexNames = df[ df['CHEM_CODE_N']==\" \" ].index\n",
    "df=df.drop(indexNames)\n",
    "indexNames = df[ df['CHEM_CODE_N']==\"-\" ].index\n",
    "df=df.drop(indexNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check the changes\n",
    "df.CHEM_CODE_N.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will make find the Price of the chemcodes of column 'CHEM_CODE_N' and make a price column in dataframe 'df'\n",
    "CHEM_CODE_N_price=[]\n",
    "chemcode=df.CHEM_CODE_N.tolist()\n",
    "for i in chemcode:\n",
    "    CHEM_CODE_price.append(float(price[i]))   \n",
    "\n",
    "df['price'] = np.array(CHEM_CODE_N_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will make a new column VALUE with approx values of chemcodes\n",
    "df['VALUE'] = df['UNIT_PPM']*df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets Drop the Unnesecary columns and reset its index\n",
    "df=df.drop(columns=['price'])\n",
    "df=df.reset_index()\n",
    "df=df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets find the most valuable minerals at a point and drop the other less valueable ones[present at the same point]\n",
    "most_valued_minerals_at_points=df.sort_values('VALUE', ascending=False).drop_duplicates(['LONGITUDE_GDA94','LATITUDE_GDA94']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By our Preliminary Testing and analysis of Datasets we found that 'most_valued_minerals_at_points' had a lot of Ca and hence was bias and not good for training. Hence we should trim some Ca's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make a DataFrame with only Ca at different points\n",
    "df_Ca=df.loc[df['CHEM_CODE']=='Ca'].drop_duplicates(['LONGITUDE_GDA94','LATITUDE_GDA94'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will sort them in descending order and make a new DataFrame with the top 100000 rows\n",
    "df_Ca=df_Ca.sort_values('VALUE', ascending=False)\n",
    "df_Ca=df_Ca.iloc[:100000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will make a index column by using reset_index() and using the index column to drop Ca from the main DataFrame\n",
    "df_Ca=df_Ca.reset_index()\n",
    "df=df.drop(df_Ca['index'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will create a final DataFrame which will be used for training\n",
    "final_df = df.sort_values('VALUE', ascending=False).drop_duplicates(['LONGITUDE_GDA94','LATITUDE_GDA94']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how it looks\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will classify UNIT_PPM into three classes \n",
    "final_df.loc[final_df['UNIT_PPM']>50000, 'UNIT_PPM_CLASS']='HIGH'\n",
    "final_df.loc[final_df['UNIT_PPM']<=50000, 'UNIT_PPM_CLASS']='MED'\n",
    "final_df.loc[final_df['UNIT_PPM']<=100, 'UNIT_PPM_CLASS']='LOW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how it looks\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally lets Drop the unnescessary columns\n",
    "final_df=final_df.drop(columns=['CHEM_CODE_N','index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now finally lets export the DataFrame as csv so that we can use for training\n",
    "final_df.to_csv('unsampled.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
